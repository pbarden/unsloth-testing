{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eVZrP5AGkLB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26533,
     "status": "ok",
     "timestamp": 1759009005192,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "0eVZrP5AGkLB",
    "outputId": "07706a01-8ed7-4714-dbdb-dd7bd88f6a28"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade unsloth torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mErQX18wGkLD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60826,
     "status": "ok",
     "timestamp": 1759009066043,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "mErQX18wGkLD",
    "outputId": "477c8b77-6144-4be7-90e8-779c8ea3db51"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IwGgaP0QGkLE",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759009066086,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "IwGgaP0QGkLE"
   },
   "outputs": [],
   "source": [
    "class CustomerDataset(Dataset):\n",
    "    def __init__(self, users, sessions, products):\n",
    "        self.users = users\n",
    "        self.sessions = sessions\n",
    "        self.products = products\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user_embedding': torch.tensor(self.users[idx], dtype=torch.float32),\n",
    "            'session_embedding': torch.tensor(self.sessions[idx], dtype=torch.float32),\n",
    "            'product_embeddings': torch.tensor(self.products[idx], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "x3X8pXKJGkLF",
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1759009066132,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "x3X8pXKJGkLF"
   },
   "outputs": [],
   "source": [
    "users = np.random.randn(100, 128)\n",
    "sessions = np.random.randn(100, 64)\n",
    "products = np.random.randn(100, 50, 128)\n",
    "\n",
    "dataset = CustomerDataset(users, sessions, products)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g0tGs7cVGkLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89080,
     "status": "ok",
     "timestamp": 1759009932448,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "g0tGs7cVGkLF",
    "outputId": "72532d79-8e4b-4aae-ff4d-3df9bc84a5a7"
   },
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    dtype=torch.float16,\n",
    "    max_seq_length=1024,\n",
    "    full_finetuning=False,\n",
    "    attn_implementation=\"eager\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ElpE27GnGkLG",
   "metadata": {
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1759010008264,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "ElpE27GnGkLG"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "proj = nn.Linear(state.shape[1], prod.shape[2]).to(device)\n",
    "\n",
    "for batch in loader:\n",
    "    user = batch['user_embedding'].to(device)\n",
    "    session = batch['session_embedding'].to(device)\n",
    "    prod = batch['product_embeddings'].to(device)\n",
    "\n",
    "    state = torch.cat([user, session], dim=1)\n",
    "    state = proj(state)\n",
    "\n",
    "    state_norm = F.normalize(state, dim=1).unsqueeze(1)\n",
    "    prod_norm  = F.normalize(prod, dim=2)\n",
    "    sim = torch.bmm(state_norm, prod_norm.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "    recommended_idx = torch.argmax(sim, dim=1)\n",
    "    recommended_products = prod[range(prod.shape[0]), recommended_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rBdHMApSK6NP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1759010109074,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "rBdHMApSK6NP",
    "outputId": "07241573-6af3-4a9f-f654-3436744d9c33"
   },
   "outputs": [],
   "source": [
    "all_recommendations = []\n",
    "\n",
    "for batch in loader:\n",
    "    user = batch['user_embedding'].to(device)\n",
    "    session = batch['session_embedding'].to(device)\n",
    "    prod = batch['product_embeddings'].to(device)\n",
    "\n",
    "    state = torch.cat([user, session], dim=1)\n",
    "    state = proj(state)\n",
    "\n",
    "    state_norm = F.normalize(state, dim=1).unsqueeze(1)\n",
    "    prod_norm  = F.normalize(prod, dim=2)\n",
    "    sim = torch.bmm(state_norm, prod_norm.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "    recommended_idx = torch.argmax(sim, dim=1)\n",
    "    recommended_products = prod[range(prod.shape[0]), recommended_idx]\n",
    "\n",
    "    for i, idx in enumerate(recommended_idx):\n",
    "      all_recommendations.append({\n",
    "          \"user_idx_in_batch\": i,\n",
    "          \"recommended_product_idx\": idx.item(),\n",
    "          \"similarity_score\": sim[i, idx].item()\n",
    "      })\n",
    "\n",
    "print(\"Done, son.\\n\")\n",
    "print(\"Sample recommendations:\")\n",
    "for r in all_recommendations[:5]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1CKkXeqcLeYr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1759010304528,
     "user": {
      "displayName": "Paul B",
      "userId": "15216216041663209619"
     },
     "user_tz": 360
    },
    "id": "1CKkXeqcLeYr",
    "outputId": "06d05483-126a-4980-9da7-9526331fdd0b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_products = 1000\n",
    "embedding_dim = 128\n",
    "product_names = [f\"{style}_{i}\" for i, style in enumerate(\n",
    "    [\"backpack\", \"handbag\", \"tote\", \"crossbody\", \"duffel\", \"messenger\", \"clutch\", \"satchel\", \"hobo\", \"bucket\"] * 100\n",
    ")]\n",
    "product_embeddings = torch.rand(num_products, embedding_dim, device=device)\n",
    "\n",
    "batch_size = 4\n",
    "num_batches = 3\n",
    "proj = torch.nn.Linear(embedding_dim * 2, embedding_dim).to(device)\n",
    "\n",
    "num_candidates = 5\n",
    "candidate_indices = random.sample(range(num_products), num_candidates)\n",
    "\n",
    "all_recommendations = {}\n",
    "\n",
    "for candidate_idx in candidate_indices:\n",
    "    candidate_name = product_names[candidate_idx]\n",
    "    candidate_embedding = product_embeddings[candidate_idx].unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "    recommendations_per_candidate = []\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        user = torch.rand(batch_size, embedding_dim, device=device)\n",
    "        session = torch.rand(batch_size, embedding_dim, device=device)\n",
    "\n",
    "        state = torch.cat([user, session], dim=1)\n",
    "        state = proj(state)\n",
    "\n",
    "        combined_state = state + candidate_embedding\n",
    "\n",
    "        state_norm = F.normalize(combined_state, dim=1).unsqueeze(1)\n",
    "        prod_norm_batch = F.normalize(product_embeddings.unsqueeze(0), dim=2).expand(batch_size, -1, -1)\n",
    "        sim = torch.bmm(state_norm, prod_norm_batch.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "        topk = torch.topk(sim, k=3, dim=1)\n",
    "        for i, indices in enumerate(topk.indices):\n",
    "            recommendations_per_candidate.append({\n",
    "                \"user_idx_in_batch\": i + batch_idx * batch_size,\n",
    "                \"candidate_product\": candidate_name,\n",
    "                \"top_recommended_products\": [product_names[idx] for idx in indices],\n",
    "                \"similarity_scores\": [sim[i, idx].item() for idx in indices]\n",
    "            })\n",
    "\n",
    "    all_recommendations[candidate_name] = recommendations_per_candidate\n",
    "\n",
    "for candidate, recs in list(all_recommendations.items())[:3]:\n",
    "    print(f\"\\nRecommendationz: {candidate}\")\n",
    "    for r in recs[:3]:\n",
    "        print(r)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
